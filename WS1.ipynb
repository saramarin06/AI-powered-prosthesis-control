{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81728ea",
   "metadata": {},
   "source": [
    "Importo funciones de los muchachos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f910c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CargaMat1 import listar_archivos_mat\n",
    "from CargaMat1 import load_emg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64bb2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEÑALES EMG\\\\SUJETO1\\\\M1_JUAN_VANEGAS.mat', 'SEÑALES EMG\\\\SUJETO1\\\\M2_JUAN_VANEGAS.mat', 'SEÑALES EMG\\\\SUJETO1\\\\M3_JUAN_VANEGAS.mat', 'SEÑALES EMG\\\\SUJETO2\\\\M1_SARA_MANCO.mat', 'SEÑALES EMG\\\\SUJETO2\\\\M2_SARA_MANCO.mat', 'SEÑALES EMG\\\\SUJETO2\\\\M3_SARA_MANCO.mat', 'SEÑALES EMG\\\\SUJETO3\\\\M1_CAMILA_ROA.mat', 'SEÑALES EMG\\\\SUJETO3\\\\M2_CAMILA_ROA.mat', 'SEÑALES EMG\\\\SUJETO3\\\\M3_CAMILA_ROA.mat', 'SEÑALES EMG\\\\SUJETO4\\\\M1_SARA_SALAMANCA.mat', 'SEÑALES EMG\\\\SUJETO4\\\\M2_SARA_SALAMANCA.mat', 'SEÑALES EMG\\\\SUJETO4\\\\M3_SARA_SALAMANCA.mat', 'SEÑALES EMG\\\\SUJETO5\\\\M1_SARA_MARIN.mat', 'SEÑALES EMG\\\\SUJETO5\\\\M2_SARA_MARIN.mat', 'SEÑALES EMG\\\\SUJETO5\\\\M3_SARA_MARIN.mat', 'SEÑALES EMG\\\\SUJETO6\\\\M1_JUAN_GIRALDO.mat', 'SEÑALES EMG\\\\SUJETO6\\\\M2_JUAN_GIRALDO.mat', 'SEÑALES EMG\\\\SUJETO6\\\\M3_JUAN_GIRALDO.mat', 'SEÑALES EMG\\\\SUJETO7\\\\M1_LEON_ARBOLEDA.mat', 'SEÑALES EMG\\\\SUJETO7\\\\M2_LEON_ARBOLEDA.mat', 'SEÑALES EMG\\\\SUJETO7\\\\M3_LEON_ARBOLEDA.mat']\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "pathlist=listar_archivos_mat(\"SEÑALES EMG\")\n",
    "print(pathlist)\n",
    "print(len(pathlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f1eb4",
   "metadata": {},
   "source": [
    "Ahora, for para cargar las señales en una lista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e1511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEÑALES EMG\\SUJETO1\\M1_JUAN_VANEGAS.mat\n",
      "SEÑALES EMG\\SUJETO1\\M2_JUAN_VANEGAS.mat\n",
      "SEÑALES EMG\\SUJETO1\\M3_JUAN_VANEGAS.mat\n",
      "SEÑALES EMG\\SUJETO2\\M1_SARA_MANCO.mat\n",
      "SEÑALES EMG\\SUJETO2\\M2_SARA_MANCO.mat\n",
      "SEÑALES EMG\\SUJETO2\\M3_SARA_MANCO.mat\n",
      "SEÑALES EMG\\SUJETO3\\M1_CAMILA_ROA.mat\n",
      "SEÑALES EMG\\SUJETO3\\M2_CAMILA_ROA.mat\n",
      "SEÑALES EMG\\SUJETO3\\M3_CAMILA_ROA.mat\n",
      "SEÑALES EMG\\SUJETO4\\M1_SARA_SALAMANCA.mat\n",
      "SEÑALES EMG\\SUJETO4\\M2_SARA_SALAMANCA.mat\n",
      "SEÑALES EMG\\SUJETO4\\M3_SARA_SALAMANCA.mat\n",
      "SEÑALES EMG\\SUJETO5\\M1_SARA_MARIN.mat\n",
      "SEÑALES EMG\\SUJETO5\\M2_SARA_MARIN.mat\n",
      "SEÑALES EMG\\SUJETO5\\M3_SARA_MARIN.mat\n",
      "SEÑALES EMG\\SUJETO6\\M1_JUAN_GIRALDO.mat\n",
      "SEÑALES EMG\\SUJETO6\\M2_JUAN_GIRALDO.mat\n",
      "SEÑALES EMG\\SUJETO6\\M3_JUAN_GIRALDO.mat\n",
      "SEÑALES EMG\\SUJETO7\\M1_LEON_ARBOLEDA.mat\n",
      "SEÑALES EMG\\SUJETO7\\M2_LEON_ARBOLEDA.mat\n",
      "SEÑALES EMG\\SUJETO7\\M3_LEON_ARBOLEDA.mat\n"
     ]
    }
   ],
   "source": [
    "lista_de_Ventanas = [] \n",
    "for i in pathlist:\n",
    "    print(i)\n",
    "    M=load_emg(i)\n",
    "    lista_de_Ventanas.append(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a1129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset 1</th>\n",
       "      <th>offset 1</th>\n",
       "      <th>onset 2</th>\n",
       "      <th>offset 2</th>\n",
       "      <th>onset 3</th>\n",
       "      <th>offset 3</th>\n",
       "      <th>SUJETO</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5,308</td>\n",
       "      <td>10,302</td>\n",
       "      <td>14,975</td>\n",
       "      <td>20,019</td>\n",
       "      <td>25,142</td>\n",
       "      <td>29,936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5,32</td>\n",
       "      <td>10,03</td>\n",
       "      <td>15,52</td>\n",
       "      <td>19,902</td>\n",
       "      <td>25,31</td>\n",
       "      <td>29,949</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5,557</td>\n",
       "      <td>10,521</td>\n",
       "      <td>15,165</td>\n",
       "      <td>20,146</td>\n",
       "      <td>25,227</td>\n",
       "      <td>29,988</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5,192</td>\n",
       "      <td>10,217</td>\n",
       "      <td>15,712</td>\n",
       "      <td>20</td>\n",
       "      <td>25,498</td>\n",
       "      <td>29,939</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5,413</td>\n",
       "      <td>10,242</td>\n",
       "      <td>15,201</td>\n",
       "      <td>20,189</td>\n",
       "      <td>25,3</td>\n",
       "      <td>29,992</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5,232</td>\n",
       "      <td>10,209</td>\n",
       "      <td>15,078</td>\n",
       "      <td>20,142</td>\n",
       "      <td>24,881</td>\n",
       "      <td>29,953</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5,425</td>\n",
       "      <td>10,646</td>\n",
       "      <td>15,314</td>\n",
       "      <td>20,319</td>\n",
       "      <td>25,359</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  onset 1 offset 1 onset 2 offset 2  onset 3 offset 3   SUJETO  Unnamed: 7  \\\n",
       "0   5,308   10,302  14,975    20,019  25,142    29,936     1.0         NaN   \n",
       "1    5,32    10,03   15,52    19,902   25,31    29,949     2.0         NaN   \n",
       "2   5,557   10,521  15,165    20,146  25,227    29,988     3.0         NaN   \n",
       "3   5,192   10,217  15,712        20  25,498    29,939     4.0         NaN   \n",
       "4   5,413   10,242  15,201    20,189    25,3    29,992     5.0         NaN   \n",
       "5   5,232   10,209  15,078    20,142  24,881    29,953     6.0         NaN   \n",
       "6   5,425   10,646  15,314    20,319  25,359        30     7.0         NaN   \n",
       "7     NaN      NaN     NaN       NaN     NaN       NaN     NaN         NaN   \n",
       "8     NaN      NaN     NaN       NaN     NaN       NaN     NaN         NaN   \n",
       "\n",
       "   Unnamed: 8  Unnamed: 9  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "5         NaN         NaN  \n",
       "6         NaN         NaN  \n",
       "7         NaN         NaN  \n",
       "8         NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tabla_promedios= pd.read_csv(\"onset_offset JUANP_SARA.csv\",sep=\";\")\n",
    "tabla_promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ba8319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Biceps   Triceps   tiempo\n",
      "0     -3.125000e-07 -0.000002   0.0000\n",
      "1     -4.562500e-06 -0.000026   0.0005\n",
      "2     -1.912500e-05 -0.000103   0.0010\n",
      "3     -4.781250e-05 -0.000241   0.0015\n",
      "4     -8.790625e-05 -0.000414   0.0020\n",
      "...             ...       ...      ...\n",
      "68384 -2.255937e-04 -0.000803  34.1920\n",
      "68385 -2.342500e-04 -0.000805  34.1925\n",
      "68386 -2.331250e-04 -0.000776  34.1930\n",
      "68387 -2.238750e-04 -0.000723  34.1935\n",
      "68388 -2.074688e-04 -0.000647  34.1940\n",
      "\n",
      "[68389 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lista_de_Ventanas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67950a55",
   "metadata": {},
   "source": [
    "Ahora creo el primer Window slicing para dividir entre contracción y relajación, este a partir del que ya había hecho de primeras, pero sin overlap ya que lo que buscamos hacer aca es solo separación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b196520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def window_slicing_1(df, window_time=5, time_col=\"tiempo\"):\n",
    "    \"\"\"\n",
    "    Divide señales en ventanas de tamaño fijo en segundos.\n",
    "    \n",
    "    df: DataFrame con una columna de tiempo y señales.\n",
    "    window_time: duración de la ventana en segundos.\n",
    "    overlap: fracción de solapamiento (0 = sin solape, 0.5 = 50%, etc.)\n",
    "    time_col: nombre de la columna de tiempo.\n",
    "    \"\"\"\n",
    "    \"\"\"duracion = df[time_col].max()  # duración total en segundos\n",
    "    num_ventanas = int(duracion // window_time)\"\"\" \n",
    "\n",
    "    ventanas = []\n",
    "    num_ventanas = 6 # se podría hacer como= duracion señal/ duración ventana para automatizar (aqui lo dejo fijo)\n",
    "    \n",
    "    for i in range(num_ventanas):\n",
    "        inicio = i * window_time\n",
    "        fin = (i+1) * window_time\n",
    "        tipo = \"relajacion\" if i % 2 == 0 else \"contraccion\"\n",
    "        \n",
    "        df_ventana = df[(df[time_col] >= inicio) & (df[time_col] < fin)].copy()  #selecciono los intervalos asi= inicio<=intervalo<fin\n",
    "        df_ventana[\"etiqueta\"] = tipo  # aqui se etiqueta cada ventana con respecto a el tipo \n",
    "        ventanas.append(df_ventana)\n",
    "    #df_individual = pd.concat(ventanas, ignore_index=True)\n",
    "    return ventanas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a744797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[            Biceps       Triceps  tiempo    etiqueta\n",
      "0    -6.250000e-08  0.000000e+00  0.0000  relajacion\n",
      "1    -5.312500e-07  2.187500e-07  0.0005  relajacion\n",
      "2    -1.750000e-06  7.500000e-07  0.0010  relajacion\n",
      "3    -3.437500e-06  1.562500e-06  0.0015  relajacion\n",
      "4    -4.968750e-06  2.531250e-06  0.0020  relajacion\n",
      "...            ...           ...     ...         ...\n",
      "9995  3.409375e-05  1.778125e-05  4.9975  relajacion\n",
      "9996  3.803125e-05  1.828125e-05  4.9980  relajacion\n",
      "9997  4.118750e-05  1.881250e-05  4.9985  relajacion\n",
      "9998  4.271875e-05  1.928125e-05  4.9990  relajacion\n",
      "9999  4.209375e-05  1.934375e-05  4.9995  relajacion\n",
      "\n",
      "[10000 rows x 4 columns],          Biceps   Triceps  tiempo     etiqueta\n",
      "10000  0.000039  0.000019  5.0000  contraccion\n",
      "10001  0.000034  0.000017  5.0005  contraccion\n",
      "10002  0.000029  0.000016  5.0010  contraccion\n",
      "10003  0.000023  0.000015  5.0015  contraccion\n",
      "10004  0.000018  0.000015  5.0020  contraccion\n",
      "...         ...       ...     ...          ...\n",
      "19995  0.000283 -0.000440  9.9975  contraccion\n",
      "19996  0.000296 -0.000399  9.9980  contraccion\n",
      "19997  0.000272 -0.000351  9.9985  contraccion\n",
      "19998  0.000211 -0.000345  9.9990  contraccion\n",
      "19999  0.000126 -0.000404  9.9995  contraccion\n",
      "\n",
      "[10000 rows x 4 columns],              Biceps   Triceps   tiempo    etiqueta\n",
      "20000  2.968750e-05 -0.000507  10.0000  relajacion\n",
      "20001 -6.318750e-05 -0.000618  10.0005  relajacion\n",
      "20002 -1.397812e-04 -0.000726  10.0010  relajacion\n",
      "20003 -1.874375e-04 -0.000831  10.0015  relajacion\n",
      "20004 -1.989062e-04 -0.000924  10.0020  relajacion\n",
      "...             ...       ...      ...         ...\n",
      "29995 -6.625000e-06  0.000024  14.9975  relajacion\n",
      "29996 -1.156250e-06  0.000023  14.9980  relajacion\n",
      "29997  6.875000e-07  0.000023  14.9985  relajacion\n",
      "29998 -1.250000e-06  0.000023  14.9990  relajacion\n",
      "29999 -5.218750e-06  0.000023  14.9995  relajacion\n",
      "\n",
      "[10000 rows x 4 columns],              Biceps   Triceps   tiempo     etiqueta\n",
      "30000 -9.093750e-06  0.000023  15.0000  contraccion\n",
      "30001 -1.162500e-05  0.000022  15.0005  contraccion\n",
      "30002 -1.300000e-05  0.000022  15.0010  contraccion\n",
      "30003 -1.412500e-05  0.000021  15.0015  contraccion\n",
      "30004 -1.534375e-05  0.000021  15.0020  contraccion\n",
      "...             ...       ...      ...          ...\n",
      "39995  2.812500e-07 -0.000214  19.9975  contraccion\n",
      "39996 -8.437500e-06 -0.000106  19.9980  contraccion\n",
      "39997 -1.643750e-05  0.000039  19.9985  contraccion\n",
      "39998 -2.300000e-05  0.000201  19.9990  contraccion\n",
      "39999 -2.809375e-05  0.000339  19.9995  contraccion\n",
      "\n",
      "[10000 rows x 4 columns],          Biceps   Triceps   tiempo    etiqueta\n",
      "40000 -0.000032  0.000416  20.0000  relajacion\n",
      "40001 -0.000036  0.000417  20.0005  relajacion\n",
      "40002 -0.000038  0.000362  20.0010  relajacion\n",
      "40003 -0.000037  0.000280  20.0015  relajacion\n",
      "40004 -0.000033  0.000201  20.0020  relajacion\n",
      "...         ...       ...      ...         ...\n",
      "49995 -0.000011  0.000013  24.9975  relajacion\n",
      "49996 -0.000025  0.000012  24.9980  relajacion\n",
      "49997 -0.000040  0.000012  24.9985  relajacion\n",
      "49998 -0.000055  0.000012  24.9990  relajacion\n",
      "49999 -0.000069  0.000012  24.9995  relajacion\n",
      "\n",
      "[10000 rows x 4 columns],          Biceps   Triceps   tiempo     etiqueta\n",
      "50000 -0.000079  0.000012  25.0000  contraccion\n",
      "50001 -0.000085  0.000012  25.0005  contraccion\n",
      "50002 -0.000087  0.000013  25.0010  contraccion\n",
      "50003 -0.000086  0.000013  25.0015  contraccion\n",
      "50004 -0.000082  0.000014  25.0020  contraccion\n",
      "...         ...       ...      ...          ...\n",
      "59995  0.000022 -0.000016  29.9975  contraccion\n",
      "59996  0.000039 -0.000024  29.9980  contraccion\n",
      "59997  0.000061 -0.000029  29.9985  contraccion\n",
      "59998  0.000082 -0.000028  29.9990  contraccion\n",
      "59999  0.000097 -0.000019  29.9995  contraccion\n",
      "\n",
      "[10000 rows x 4 columns]]\n",
      "la cantidad de ventanas en esta lista es de 6\n"
     ]
    }
   ],
   "source": [
    "ventanas1= window_slicing_1(M)\n",
    "print(ventanas1)\n",
    "print(f\"la cantidad de ventanas en esta lista es de {len(ventanas1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e3008",
   "metadata": {},
   "source": [
    "Cada ventana es de 10.000 muestras ya que son 5 segundos y cada muestra tiene una duración de 0.0005. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002de153",
   "metadata": {},
   "source": [
    "Falta aplicar la metrica correcta a cada ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8d176",
   "metadata": {},
   "source": [
    "INTENTARÉ GENRAR EL WS PARA ETIQUETADO CON RSPECTO AL ONSEY Y OFFSET \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72191f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  onset 1 offset 1 onset 2 offset 2  onset 3 offset 3   SUJETO  Unnamed: 7  \\\n",
      "0   5,308   10,302  14,975    20,019  25,142    29,936     1.0         NaN   \n",
      "1    5,32    10,03   15,52    19,902   25,31    29,949     2.0         NaN   \n",
      "2   5,557   10,521  15,165    20,146  25,227    29,988     3.0         NaN   \n",
      "3   5,192   10,217  15,712        20  25,498    29,939     4.0         NaN   \n",
      "4   5,413   10,242  15,201    20,189    25,3    29,992     5.0         NaN   \n",
      "\n",
      "   Unnamed: 8  Unnamed: 9  \n",
      "0         NaN         NaN  \n",
      "1         NaN         NaN  \n",
      "2         NaN         NaN  \n",
      "3         NaN         NaN  \n",
      "4         NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar el CSV\n",
    "csv_path = \"onset_offset JUANP_SARA.csv\"\n",
    "df = pd.read_csv(csv_path, sep=\";\")\n",
    "\n",
    "# 2. Ver las primeras filas para confirmar estructura\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9f3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "diccionario_sujetos = {}\n",
    "\n",
    "for path in pathlist:\n",
    "    # Buscar el nombre del sujeto en la ruta (por ejemplo: SUJETO1, SUJETO2, etc.)\n",
    "    match = re.search(r\"(SUJETO\\d+)\", path)\n",
    "    if match:\n",
    "        clave = match.group(1)\n",
    "        # Crear la clave si no existe y agregar el path\n",
    "        diccionario_sujetos.setdefault(clave, []).append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c187f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "\n",
    "def etiquetar_senales(diccionario_sujetos, csv_path):\n",
    "    \"\"\"\n",
    "    Etiqueta señales EMG (.mat) de cada sujeto según los onsets y offsets \n",
    "    definidos en un archivo CSV.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    diccionario_sujetos : dict\n",
    "        Diccionario con las rutas de los archivos .mat por sujeto.\n",
    "        Ejemplo: {'SUJETO1': ['SEÑALES EMG/SUJETO1/M1_JUAN.mat', ...]}\n",
    "        \n",
    "    csv_path : str\n",
    "        Ruta del archivo CSV que contiene columnas:\n",
    "        sujeto, onset1, offset1, onset2, offset2, onset3, offset3, ...\n",
    "        \n",
    "    Retorna\n",
    "    -------\n",
    "    resultados : dict\n",
    "        Diccionario con la estructura:\n",
    "        {\n",
    "            'SUJETO1': {\n",
    "                'M1_JUAN': {\n",
    "                    'voltajes': [...],\n",
    "                    'etiquetas': [...]\n",
    "                },\n",
    "                ...\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    resultados = {}\n",
    "\n",
    "    for _, fila in df.iterrows():\n",
    "        sujeto = str(fila[\"sujeto\"]).strip()\n",
    "\n",
    "        if sujeto not in diccionario_sujetos:\n",
    "            print(f\"⚠️ No se encontraron señales para {sujeto}\")\n",
    "            continue\n",
    "\n",
    "        # Extraer onsets y offsets válidos\n",
    "        onsets = [int(fila[f\"onset{i}\"]) for i in range(1, 4) if not pd.isna(fila.get(f\"onset{i}\", np.nan))]\n",
    "        offsets = [int(fila[f\"offset{i}\"]) for i in range(1, 4) if not pd.isna(fila.get(f\"offset{i}\", np.nan))]\n",
    "\n",
    "        resultados[sujeto] = {}\n",
    "\n",
    "        for mat_path in diccionario_sujetos[sujeto]:\n",
    "            # Cargar archivo .mat\n",
    "            mat_data = sio.loadmat(mat_path)\n",
    "            signal_key = [k for k in mat_data.keys() if not k.startswith(\"__\")][0]\n",
    "            señal = np.squeeze(mat_data[signal_key])\n",
    "\n",
    "            etiquetas = np.array([\"relajacion\"] * len(señal), dtype=object)\n",
    "\n",
    "            # Marcar contracción en los intervalos\n",
    "            for on, off in zip(onsets, offsets):\n",
    "                etiquetas[on:off] = \"contraccion\"\n",
    "\n",
    "            nombre_archivo = os.path.splitext(os.path.basename(mat_path))[0]\n",
    "            resultados[sujeto][nombre_archivo] = {\n",
    "                \"voltajes\": señal,\n",
    "                \"etiquetas\": etiquetas\n",
    "            }\n",
    "\n",
    "            print(f\"✅ {sujeto} - {nombre_archivo}: Etiquetado completado\")\n",
    "\n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "056937bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sujeto'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'sujeto'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Supongamos que ya generaste tu diccionario de señales:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# diccionario_sujetos = {\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     'SUJETO1': ['SEÑALES EMG/SUJETO1/M1_JUAN_VANEGAS.mat', 'SEÑALES EMG/SUJETO1/M2_JUAN_VANEGAS.mat'],\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#     'SUJETO2': ['SEÑALES EMG/SUJETO2/M1_SARA_MANCO.mat']\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[32m      7\u001b[39m csv_path = \u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mASUS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mOneDrive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mEscritorio\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mPython\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mAutomatizacion\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mAUTO 2\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mAI PROYECT\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mAI-powered-prosthesis-control\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33monset_offset JUANP_SARA.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m resultados = \u001b[43metiquetar_senales\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiccionario_sujetos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36metiquetar_senales\u001b[39m\u001b[34m(diccionario_sujetos, csv_path)\u001b[39m\n\u001b[32m     38\u001b[39m resultados = {}\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, fila \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     sujeto = \u001b[38;5;28mstr\u001b[39m(\u001b[43mfila\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msujeto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m).strip()\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sujeto \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m diccionario_sujetos:\n\u001b[32m     44\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️ No se encontraron señales para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msujeto\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'sujeto'"
     ]
    }
   ],
   "source": [
    "# Supongamos que ya generaste tu diccionario de señales:\n",
    "# diccionario_sujetos = {\n",
    "#     'SUJETO1': ['SEÑALES EMG/SUJETO1/M1_JUAN_VANEGAS.mat', 'SEÑALES EMG/SUJETO1/M2_JUAN_VANEGAS.mat'],\n",
    "#     'SUJETO2': ['SEÑALES EMG/SUJETO2/M1_SARA_MANCO.mat']\n",
    "# }\n",
    "\n",
    "csv_path = \"C:\\\\Users\\\\ASUS\\\\OneDrive\\\\Escritorio\\\\Python\\\\Automatizacion\\\\AUTO 2\\\\AI PROYECT\\\\AI-powered-prosthesis-control\\\\onset_offset JUANP_SARA.csv\"\n",
    "\n",
    "resultados = etiquetar_senales(diccionario_sujetos, csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
